{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "660bcd02-6815-4b2e-9272-a26a8685a6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:[0.1119, 0.20091, -0.09832]\n",
      "Weight Deltas:[-1.189999999999999, -0.09099999999999994, -0.16799999999999987]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The order of \"pred - true\" vs \"true - pred\" when calculating the \"error\" and \"delta\" can technically be changed, but it will affect downstream calculations, particularly the sign of the gradients during backpropagation. Here's how:\n",
    "\n",
    "1. Error\n",
    "For squared error loss (pred−true)^2 , the order doesn't matter because squaring removes any negative sign. You could also use (true−pred)^2 and the outcome for the error would be the same.\n",
    "\n",
    "2. Delta\n",
    "The \"delta\" is essentially the derivative of the error with respect to the predicted value. In simple terms, it's the difference between your predicted and true values. The order matters here:\n",
    "\n",
    "If you use delta=pred−true, a positive delta will indicate your model's prediction is too high, and a negative delta will indicate the prediction is too low.\n",
    "\n",
    "If you use delta=true−pred, the meaning of positive and negative deltas flips. In this case, a positive delta will indicate that the model's prediction is too low, and a negative delta would indicate the prediction is too high.\n",
    "\n",
    "So you could change the order, but if you do, be sure to also change how you update your weights. Currently, your weights are updated as follows:\n",
    "\n",
    "weights[i] -= alpha * weight_deltas[i]\n",
    "\n",
    "If you switched the order to delta=true−pred, you'd also want to change the weight update rule to:\n",
    "\n",
    "weights[i] += alpha * weight_deltas[i]  # Notice the '+=' instead of '-='\n",
    "\n",
    "This way, the weight updates would have the appropriate sign to correct the error.\n",
    "\n",
    "why if it's \"delta=pred−true\" then has to be \"-=\" in \"weights[i] -= alpha * weight_deltas[i]\"?\n",
    "\n",
    "The choice of using -= or += in updating the weights depends on how you've defined your loss function and its gradient, which ultimately directs how the optimization step should be carried out.\n",
    "\n",
    "In the case of δ=pred−true:\n",
    "A positive delta means the prediction is too high and needs to be reduced.\n",
    "A negative delta means the prediction is too low and needs to be increased.\n",
    "To make the adjustments:\n",
    "\n",
    "For a positive delta, you'd want to decrease the weights slightly to reduce the prediction. Thus, you use -= in the update rule.\n",
    "For a negative delta, the -= in the update rule actually increases the weights because the weight_deltas themselves would be negative.\n",
    "In the case of δ=true−pred:\n",
    "A positive delta means the prediction is too low.\n",
    "A negative delta means the prediction is too high.\n",
    "If you were to switch to this definition of delta, you would use += to update the weights in the opposite direction to correct the error.\n",
    "\n",
    "In summary, the choice of -= or += in the weight update rule depends on how you've defined your error term and which direction you want to adjust your weights in. The goal is to make adjustments that minimize the error.\n",
    "\n",
    "Q:So in convention we write 'delta = pred - true', but before excute the code how could we know that it's '-=' or '+=' in 'weights[i] -= alpha * weight_deltas[i]'? \n",
    "we assume pred is too big then weight_deltas value is suppose to be positive, but what if pred is actually too small then weight_delta value is actually negative?\n",
    "\n",
    "The sign in the weight update step weights[i] -= alpha * weight_deltas[i] is determined by how you define your loss function and how you calculate the gradients (weight deltas) with respect to that loss function. This is a part of the backpropagation algorithm.\n",
    "\n",
    "In the example you provided, you used mean squared error as your loss function, calculated as (pred - true)**2. The gradient of this loss with respect to pred is 2*(pred - true), or simplified, pred - true (since we often ignore constant scaling factors like 2 when performing gradient descent).\n",
    "\n",
    "The gradient tells us the direction in which the function's output (the error) increases the fastest. To minimize the error, we want to go in the opposite direction, which is why we subtract the gradient from the weights: weights[i] -= alpha * weight_deltas[i].\n",
    "\n",
    "So, even if pred is too small (making delta = pred - true negative), the weight update rule remains the same. The negative delta will result in a negative weight_delta, and when you subtract a negative number, you're effectively moving the weight in the positive direction, \n",
    "which is what you'd want in the case that pred is smaller than true.\n",
    "\n",
    "In summary, the convention takes care of these details automatically, and you don't have to manually check the signs or change the update rule.\n",
    "\"\"\"\n",
    "\n",
    "weights = [0.1, 0.2, -.1] \n",
    "\n",
    "toes =  [8.5, 9.5, 9.9, 9.0]\n",
    "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "win_or_lose_binary = [1, 1, 0, 1]\n",
    "\n",
    "true = win_or_lose_binary[0]\n",
    "\n",
    "alpha = 0.01\n",
    "\n",
    "input = [toes[0],wlrec[0],nfans[0]]\n",
    "\n",
    "def w_sum(a,b):\n",
    "    assert(len(a) == len(b))\n",
    "    output = 0\n",
    "\n",
    "    for i in range(len(a)):\n",
    "        output += (a[i] * b[i])\n",
    "\n",
    "    return output\n",
    "\n",
    "def neural_network(input,weights):\n",
    "    pred = w_sum(input,weights)\n",
    "    return pred\n",
    "\n",
    "# Input corresponds to every entry\n",
    "# for the first game of the season.\n",
    "\n",
    "pred = neural_network(input,weights)\n",
    "error = (pred - true) ** 2\n",
    "delta = pred - true\n",
    "\n",
    "def ele_mul(number,vector):\n",
    "    output = [0,0,0]\n",
    "\n",
    "    assert(len(output) == len(vector))\n",
    "\n",
    "    for i in range(len(vector)):\n",
    "        output[i] = number * vector[i]\n",
    "\n",
    "    return output\n",
    "\n",
    "weight_deltas = ele_mul(delta,input)\n",
    "\n",
    "for i in range(len(weights)):\n",
    "    weights[i] -= alpha * weight_deltas[i]\n",
    "    \n",
    "print(\"Weights:\" + str(weights))\n",
    "print(\"Weight Deltas:\" + str(weight_deltas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceec85e4-6598-4699-afa1-09d6e7f66ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interation: 1\n",
      "Pred: 0.8600000000000001\n",
      "Error: 0.01959999999999997\n",
      "Delta: -0.1399999999999999\n",
      "Weights:[0.1, 0.2, -0.1]\n",
      "Weights deltas: [-1.189999999999999, -0.09099999999999994, -0.16799999999999987]\n",
      "\n",
      "Interation: 2\n",
      "Pred: 0.9637574999999999\n",
      "Error: 0.0013135188062500048\n",
      "Delta: -0.036242500000000066\n",
      "Weights:[0.1119, 0.20091, -0.09832]\n",
      "Weights deltas: [-0.30806125000000056, -0.023557625000000044, -0.04349100000000008]\n",
      "\n",
      "Interation: 3\n",
      "Pred: 0.9906177228125002\n",
      "Error: 8.802712522307997e-05\n",
      "Delta: -0.009382277187499843\n",
      "Weights:[0.11498061250000001, 0.20114557625, -0.09788509000000001]\n",
      "Weights deltas: [-0.07974935609374867, -0.006098480171874899, -0.011258732624999811]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Let's watch several steps of leaning\n",
    "def neural_network(input, weights):\n",
    "  out = 0\n",
    "  for i in range(len(input)):\n",
    "    out += (input[i] * weights[i])\n",
    "  return out\n",
    "\n",
    "def ele_mul(scalar, vector):\n",
    "  out = [0,0,0]\n",
    "  for i in range(len(out)):\n",
    "    out[i] = vector[i] * scalar\n",
    "  return out\n",
    "\n",
    "toes =  [8.5, 9.5, 9.9, 9.0]\n",
    "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "win_or_lose_binary = [1, 1, 0, 1]\n",
    "true = win_or_lose_binary[0]\n",
    "\n",
    "alpha = 0.01\n",
    "weights = [0.1, 0.2, -.1]\n",
    "input = [toes[0],wlrec[0],nfans[0]]\n",
    "\n",
    "for iter in range (3):\n",
    "    pred = neural_network(input,weights)\n",
    "    error = (pred - true)**2\n",
    "    delta = pred - true\n",
    "\n",
    "    weight_deltas = ele_mul(delta,input)\n",
    "\n",
    "    print(\"Interation: \" + str(iter+1))\n",
    "    print(\"Pred: \" + str(pred))\n",
    "    print(\"Error: \" + str(error))\n",
    "    print(\"Delta: \" + str(delta))\n",
    "    print(\"Weights:\" + str(weights))\n",
    "    print(\"Weights deltas: \" + str(weight_deltas))\n",
    "    print()\n",
    "\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] -= alpha * weight_deltas[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85e966b0-dcbe-44e2-bb41-b5ff77b1e08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interation: 1\n",
      "Pred: 0.8600000000000001\n",
      "Error: 0.01959999999999997\n",
      "Delta: -0.1399999999999999\n",
      "Weights:[0.1, 0.2, -0.1]\n",
      "Weights deltas: [0, -0.09099999999999994, -0.16799999999999987]\n",
      "\n",
      "Interation: 2\n",
      "Pred: 0.9382250000000001\n",
      "Error: 0.003816150624999989\n",
      "Delta: -0.06177499999999991\n",
      "Weights:[0.1, 0.2273, -0.04960000000000005]\n",
      "Weights deltas: [0, -0.040153749999999946, -0.07412999999999989]\n",
      "\n",
      "Interation: 3\n",
      "Pred: 0.97274178125\n",
      "Error: 0.000743010489422852\n",
      "Delta: -0.027258218750000007\n",
      "Weights:[0.1, 0.239346125, -0.02736100000000008]\n",
      "Weights deltas: [0, -0.017717842187500006, -0.032709862500000006]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Freezing One Weight - What Does It Do?\n",
    "def neural_network(input, weights):\n",
    "  out = 0\n",
    "  for i in range(len(input)):\n",
    "    out += (input[i] * weights[i])\n",
    "  return out\n",
    "\n",
    "def ele_mul(scalar, vector):\n",
    "  out = [0,0,0]\n",
    "  for i in range(len(out)):\n",
    "    out[i] = vector[i] * scalar\n",
    "  return out\n",
    "\n",
    "toes =  [8.5, 9.5, 9.9, 9.0]\n",
    "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "win_or_lose_binary = [1, 1, 0, 1]\n",
    "true = win_or_lose_binary[0]\n",
    "\n",
    "alpha = 0.3\n",
    "weights = [0.1, 0.2, -.1]\n",
    "input = [toes[0],wlrec[0],nfans[0]]\n",
    "\n",
    "for iter in range (3):\n",
    "    pred = neural_network(input,weights)\n",
    "    error = (pred - true)**2\n",
    "    delta = pred - true\n",
    "\n",
    "    weight_deltas = ele_mul(delta,input)\n",
    "    weight_deltas[0] = 0\n",
    "    \n",
    "    print(\"Interation: \" + str(iter+1))\n",
    "    print(\"Pred: \" + str(pred))\n",
    "    print(\"Error: \" + str(error))\n",
    "    print(\"Delta: \" + str(delta))    \n",
    "    print(\"Weights:\" + str(weights))\n",
    "    print(\"Weights deltas: \" + str(weight_deltas))\n",
    "    print()\n",
    "\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] -= alpha * weight_deltas[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e2e7219-c7bf-439f-8271-749380d1b70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:  [0.293825, 0.25655, 0.868475]\n",
      "Weight_deltas:  [0.061750000000000006, -0.5655, 0.3152500000000001]\n"
     ]
    }
   ],
   "source": [
    "# Gradient Descent Learning with Multiple Outputs\n",
    "# Instead of predicting just \n",
    "# whether the team won or lost, \n",
    "# now we're also predicting whether\n",
    "# they are happy/sad AND the\n",
    "# percentage of the team that is\n",
    "# hurt. We are making this\n",
    "# prediction using only\n",
    "# the current win/loss record.\n",
    "\n",
    "weights = [0.3, 0.2, 0.9] \n",
    "\n",
    "wlrec = [0.65, 1.0, 1.0, 0.9] # win or lose record\n",
    "\n",
    "hurt  = [0.1, 0.0, 0.0, 0.1]\n",
    "win   = [  1,   1,   0,   1]\n",
    "sad   = [0.1, 0.0, 0.1, 0.2]\n",
    "\n",
    "true = [hurt[0],win[0],sad[0]]\n",
    "input = wlrec[0]\n",
    "\n",
    "alpha = 0.1\n",
    "\n",
    "error = [0, 0, 0] \n",
    "delta = [0, 0, 0]\n",
    "\n",
    "def ele_mul(scalar,vector):\n",
    "    output = [0,0,0]\n",
    "    for i in range(len(vector)):\n",
    "        output[i] = scalar * vector[i]\n",
    "    return output\n",
    "\n",
    "def neural_network(input,weights):\n",
    "    predication = ele_mul(input,weights)\n",
    "    return predication\n",
    "\n",
    "pred = neural_network(input,weights)\n",
    "\n",
    "for i in range(len(true)): \n",
    "    error[i] = (pred[i] - true[i])**2\n",
    "    delta[i] = pred[i] - true[i]\n",
    "\n",
    "def scalar_ele_mul(scalar,vector):\n",
    "    output = [0,0,0]\n",
    "    assert(len(output) == len(vector))\n",
    "    for i in range(len(vector)):\n",
    "        output[i] = scalar * vector[i]\n",
    "    return output\n",
    "\n",
    "weight_deltas = scalar_ele_mul(input,delta)\n",
    "\n",
    "for i in range(len(weights)):\n",
    "    weights[i] -= alpha * weight_deltas[i]\n",
    "\n",
    "print(\"Weights: \", str(weights))\n",
    "print(\"Weight_deltas: \", str(weight_deltas))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7233a7da-cf9a-455a-aade-aeeda461efd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred: [0.555, 0.9800000000000001, 0.9650000000000001]\n"
     ]
    }
   ],
   "source": [
    "#Gradient Descent with Multiple Inputs & Outputs\n",
    "            #toes %win #fans\n",
    "weights = [ [0.1, 0.1, -0.3],#hurt?\n",
    "            [0.1, 0.2, 0.0], #win?\n",
    "            [0.0, 1.3, 0.1] ]#sad?\n",
    "\n",
    "toes  = [8.5, 9.5, 9.9, 9.0]\n",
    "wlrec = [0.65,0.8, 0.8, 0.9]\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "hurt  = [0.1, 0.0, 0.0, 0.1]\n",
    "win   = [  1,   1,   0,   1]\n",
    "sad   = [0.1, 0.0, 0.1, 0.2]\n",
    "\n",
    "alpha = 0.01\n",
    "error = [0, 0, 0] \n",
    "delta = [0, 0, 0]\n",
    "\n",
    "input = [toes[0],wlrec[0],nfans[0]]\n",
    "true = [hurt[0],win[0],sad[0]]\n",
    "\n",
    "def w_sum(vectora,vectorb):\n",
    "    assert(len(vectora) == len(vectorb))\n",
    "    output = 0\n",
    "    for i in range(len(vectora)):\n",
    "        output += (vectora[i] * vectorb[i])\n",
    "    return output\n",
    "\n",
    "def vect_mul_matrix(vector,matrix):\n",
    "    output = [0,0,0]\n",
    "    assert(len(vector) == len(matrix))\n",
    "    for i in range(len(matrix)):\n",
    "        output[i] = w_sum(vector,matrix[i])\n",
    "    return output\n",
    "\n",
    "def neural_network(input,weights):\n",
    "    pred = vect_mul_matrix(input,weights)\n",
    "    return pred\n",
    "\n",
    "pred = neural_network(input,weights)\n",
    "\n",
    "print(\"Pred: \" + str(pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32962fdf-84e8-48d9-b192-390482d88cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights: [[0.061325, 0.0970425, -0.30546], [0.1017, 0.20013, 0.00023999999999999887], [-0.07352500000000001, 1.2943775, 0.08962]]\n",
      "Weight_deltas: [[ 3.8675   0.29575  0.546  ]\n",
      " [-0.17    -0.013   -0.024  ]\n",
      " [ 7.3525   0.56225  1.038  ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#Numpy version Gradient Descent with Multiple Inputs & Outputs\n",
    "            #toes %win #fans\n",
    "weights = [ [0.1, 0.1, -0.3],#hurt?\n",
    "            [0.1, 0.2, 0.0], #win?\n",
    "            [0.0, 1.3, 0.1] ]#sad?\n",
    "\n",
    "toes  = [8.5, 9.5, 9.9, 9.0]\n",
    "wlrec = [0.65,0.8, 0.8, 0.9]\n",
    "nfans = [1.2, 1.3, 0.5, 1.0]\n",
    "\n",
    "hurt  = [0.1, 0.0, 0.0, 0.1]\n",
    "win   = [  1,   1,   0,   1]\n",
    "sad   = [0.1, 0.0, 0.1, 0.2]\n",
    "\n",
    "alpha = 0.01\n",
    "error = [0, 0, 0] \n",
    "delta = [0, 0, 0]\n",
    "\n",
    "input = [toes[0],wlrec[0],nfans[0]]\n",
    "true = [hurt[0],win[0],sad[0]]\n",
    "\"\"\"\n",
    "def w_sum(vectora,vectorb):\n",
    "    output = 0\n",
    "    assert(len(vectora) == len(vectorb))\n",
    "    for i in range(len(vectora)):\n",
    "        output += (vectora[i] * vectorb[i])\n",
    "    return output\n",
    "\n",
    "def vect_mul_matrix(vector,matrix):\n",
    "    output = [0,0,0]\n",
    "    assert(len(vector) == len(matrix))\n",
    "    for i in range(len(matrix)):\n",
    "        output[i] = w_sum(vector,matrix[i]) \n",
    "    return output\n",
    "\"\"\"\n",
    "\n",
    "def neural_network(input,weights):\n",
    "    pred = np.dot(input,np.array(weights).T) #also can write as vector.dot(np.array(matrix).T), also can use above vect_mul_matrix\n",
    "    return pred\n",
    "\n",
    "pred = neural_network(input,weights)\n",
    "\n",
    "for i in range(len(true)):\n",
    "    error[i] = (pred[i] - true[i])**2\n",
    "    delta[i] = pred[i] - true[i] \n",
    "\n",
    "def outer_prod(a, b): #calculate every elements of result matrix by outer_prod \n",
    "    \n",
    "    # just a matrix of zeros\n",
    "    out = np.zeros((len(a), len(b)))\n",
    "\n",
    "    for i in range(len(a)):\n",
    "        for j in range(len(b)):\n",
    "            out[i][j] = a[i] * b[j]\n",
    "    return out\n",
    "\n",
    "weight_deltas = outer_prod(delta,input)\n",
    "\n",
    "for i in range(len(weights)):\n",
    "    for j in range(len(weights[0])):\n",
    "        weights[i][j] -= alpha * weight_deltas[i][j]\n",
    "\n",
    "print(\"Weights: \" + str(weights))\n",
    "print(\"Weight_deltas: \" + str(weight_deltas))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab89bb40-54c0-4e2f-b72c-20b047f6658e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986f4c3e-2560-45f6-9e3e-6f51ba447f00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
